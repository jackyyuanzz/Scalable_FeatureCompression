{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from compressai.models.priors import MeanScaleHyperprior\n",
    "from compressai.models.priors import ScaleHyperprior, CompressionModel\n",
    "from compressai.entropy_models import EntropyBottleneck, GaussianConditional\n",
    "\n",
    "from compressai.models.utils import conv, deconv, update_registered_buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantize_Hyperprior(ScaleHyperprior):\n",
    "    r\"\"\"Scale Hyperprior with non zero-mean Gaussian conditionals from D.\n",
    "    Minnen, J. Balle, G.D. Toderici: `\"Joint Autoregressive and Hierarchical\n",
    "    Priors for Learned Image Compression\" <https://arxiv.org/abs/1809.02736>`_,\n",
    "    Adv. in Neural Information Processing Systems 31 (NeurIPS 2018).\n",
    "\n",
    "    Args:\n",
    "        N (int): Number of channels\n",
    "        M (int): Number of channels in the expansion layers (last layer of the\n",
    "            encoder and last layer of the hyperprior decoder)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, M = 192, N = 128, **kwargs):\n",
    "        CompressionModel.__init__(self, entropy_bottleneck_channels = N, **kwargs)\n",
    "        \n",
    "        self.h_a = nn.Sequential(\n",
    "            conv(M, N, stride=1, kernel_size=3),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            conv(N, N),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            conv(N, N),\n",
    "        )\n",
    "\n",
    "        self.h_s = nn.Sequential(\n",
    "            deconv(N, M),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            deconv(M, M * 3 // 2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            conv(M * 3 // 2, M * 2, stride=1, kernel_size=3),\n",
    "        )\n",
    "        self.gaussian_conditional = GaussianConditional(None)\n",
    "        self.N = int(N)\n",
    "        self.M = int(M)\n",
    "\n",
    "    def forward(self, y):\n",
    "        z = self.h_a(y)\n",
    "        z_hat, z_likelihoods = self.entropy_bottleneck(z)\n",
    "        gaussian_params = self.h_s(z_hat)\n",
    "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
    "        y_hat, y_likelihoods = self.gaussian_conditional(y, scales_hat, means=means_hat)\n",
    "\n",
    "        return {\n",
    "            \"likelihoods\": {\"y\": y_likelihoods, \"z\": z_likelihoods},\n",
    "            \"yhat\": y_hat,\n",
    "        }\n",
    "\n",
    "    def compress(self, y):\n",
    "        z = self.h_a(y)\n",
    "\n",
    "        z_strings = self.entropy_bottleneck.compress(z)\n",
    "        z_hat = self.entropy_bottleneck.decompress(z_strings, z.size()[-2:])\n",
    "\n",
    "        gaussian_params = self.h_s(z_hat)\n",
    "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
    "        indexes = self.gaussian_conditional.build_indexes(scales_hat)\n",
    "        y_strings = self.gaussian_conditional.compress(y, indexes, means=means_hat)\n",
    "        return {\"strings\": [y_strings, z_strings], \"shape\": z.size()[-2:]}\n",
    "\n",
    "    def decompress(self, strings, shape):\n",
    "        assert isinstance(strings, list) and len(strings) == 2\n",
    "        z_hat = self.entropy_bottleneck.decompress(strings[1], shape)\n",
    "        gaussian_params = self.h_s(z_hat)\n",
    "        scales_hat, means_hat = gaussian_params.chunk(2, 1)\n",
    "        indexes = self.gaussian_conditional.build_indexes(scales_hat)\n",
    "        y_hat = self.gaussian_conditional.decompress(\n",
    "            strings[0], indexes, means=means_hat\n",
    "        )\n",
    "        return {\"y_hat\": y_hat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128, 10, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Quantize_Hyperprior()\n",
    "y = torch.rand((10,192,40,40))\n",
    "out = a(y)\n",
    "out['yhat'].shape\n",
    "out['likelihoods']['z'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_env]",
   "language": "python",
   "name": "conda-env-torch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
